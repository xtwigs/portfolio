import PostHeader from "@/components/post-header";

<PostHeader
  className="mb-32"
  title="Future of Artificial Intelligence"
  date="2022.04.02"
  description="admission essay for my master's at TUM"
/>

# Introduction

There's no denying we live in an era where Artificial Intelligence (AI)
is becoming predominant. The recent advancements in computer hardware
and manufacturing processes have made it possible for technology to
permeate our lives in every aspect. It is now an essential aspect of our
professional endeavors, our leisure and entertainment, and even our
social interaction as humans.

Moreover, it seems like the line between what is authentic human
behavior and technologically influenced behavior is bound to get
blurrier. With the introduction of AI to the public, we could see how
the future could feature plenty of dystopian concepts. For example,
instances where people are interacting \"humanly\" with intelligent
systems [^@leviathan_matias_2018], ignorant of the other party's lack of
humanity. We should observe a plethora of jobs being wiped out because
someone developed an AI that controls a system or robot to perform a
specific task, an AI that's extremely more skilled and capable than any
human could possibly be. All this is sure to shake up how society works,
and will that be a positive change for the future of mankind?

# What is AI History?

Intelligent systems have originated and have been discussed for most of
the twentieth century, but the exact date where they have begun to be
discussed is unknown. One reason for this may very well be that, the
definition of AI is not precise. Is a machine learning algorithm
intelligent? A system computing the solution to a search problem doesn't
seem very intelligent. On the contrary, it's only, and strictly, the
following of rules laid out by someone who wrote its software.

## Early Days

A lot of the early work on AI was inspired from the premise that an
artificial brain could be constructed. It was just discovered that the
neurons found in our brain responded to electrical stimuli
[@Hodgkin1952], therefore, the idea that we could somehow simulate this
network didn't seem too far-fetched.

Furthermore, Alan Turing proposed that machine thinking could be
feasible [@TURING1950], since the only way to test its intelligence
would be through conversation. This prompted prominent researchers at
the time to analyze this topic in more detail: led by Dr. John McCarthy,
several experts met in what is known as the Dartmouth Summer Research
Project on Artificial Intelligence
[@McCarthy_Minsky_Rochester_Shannon_2006]. In 1956, they discussed how
to transfer human reasoning to a machine, effectively founding the AI
research field, where they would go on to become leading researchers for
decades to come.

What followed was extreme excitement over the potential of artificial
intelligence, which became further incentivized by the appearance of
innovative systems such as ELIZA [@Weizenbaum1966] or the Perceptron
[@Rosenblatt1958], or even the multitude of optimism coming from lead
researchers [@Crevier1993-bt].

Government institutions were racing to invest and capitalize in these
technologies, but couldn't help but feel disappointed when, in the
1970s, they failed to produce meaningful results. Moreover, Minsky and
Papert publishing a book [@Minsky1987-qg] affirming the Perceptron's
limitations and James Lighthill releasing the famous \"Lighthill
report\" [@lighthill1973artificial] put the final nail in the coffin. In
the eyes of these institutions, public money was now misplaced and
research funding to AI was to be cut, leading to the remarkable first AI
winter.

In fact, this wave of optimism and letdowns happened once more: expert
systems dealing with a subset of knowledge appeared
[@reactor][@Shortliffe1975] in the 1980s. They were much more
practically inclined and their applications in real life were plausible,
which excited investors and the general public. However, they still had
to deal with the lack of proper computing power and ended up suffering
from much of the same fate as their predecessors.

Only in the 90s and early 2000s was AI to pick up steam again,
accompanying the rise of the personal computer and overall computing
abilities. Deep Blue remarkably beat Garry Kasparov in the game of chess
[@Newborn2003], signaling to all the people watching on television and
the overall world, that AI was here to stay.

## Modern systems

Reflecting upon history, we can't deny the current AI summer we live in:
the technological limitations of the past are generally suppressed,
Moore's Law [@4785860] has continued to hold until very much recently;
investment is continuing to grow at an astonishing rate [@staff_2021];
research output is sky-high due to the democratization of Deep Learning
tools (Pytorch, Tensorflow, among others), the topic being in the
limelight of public attention and an abundance of private research
investment [@DBLP:journals/corr/abs-2103-06312].

Our intelligent systems have now reached unprecedented scale, consider
PaLM [@https://doi.org/10.48550/arxiv.2204.02311] with it's measly 540
billion parameters for instance. Along with their size, their inherent
capabilities have also reached superhuman level in specific domains,
take AlphaGo [@Silver2016] who beat the reigning Go champion, a game
notoriously difficult to \"solve\" with classical search problems.
Furthermore, this particular model's successors are landmark
achievements by themselves, MuZero [@Schrittwieser2020] can also play Go
with superhuman ability, except that it can also play Chess, Shogi and
Atari, and no one even coded these game's rules into it, it just learned
them.

With all this progress in mind, what sets this era of AI apart from the
past is the sheer amount of private investment: most of the research
developments are happening in institutions with ties to global
enterprises, or directly under their tutelage (DeepMind and Google AI,
OpenAI, Meta AI and many others). Since it's extremely profitable
[@dickson_2021], almost every technological giant has an AI division.

In stark contrast with the winters of the past, computation is
accessible through our phones, meaning that AI models have a much larger
reach than the lab environment where they were built. When users easily
interact with large language models, be it for translation or a personal
assistant, and effectively improve their every day lives, they
illustrate that AI models now have practical use cases.

# Future

Regarding the future of AI, with computing power continuously
increasing, we should observe a rather accelerated rate of technological
advancements, spurring new and exciting use cases for AI. Therefore,
before making predictions on what the future may hold, we should
consider some aspects: the continued permeation of technology into our
every day lives, the development of groundbreaking systems and, the
regulations that will need to accompany these innovations.

## Immersion

Firstly, there are some avenues for technology to become even more
prominent in our direct lives: our smartphones could morph into
something even more intrusive than what they currently are, making us
even more susceptible to the technological zombies phenomena
[@al-khalil_2020]; we could live imaginary lives in an imaginary world
[@the_wall_street_journal_2022]; we could interact with technology
directly through our brains [@Musk2019], producing sensory data and
being fed constant feedback on the world around us and, most
importantly, profoundly altering our brain's structural framework.

The immersion of human beings in technology provides many opportunities
for AI to be useful. From originating an absurd amount of data to
creating more occasions for human-AI interaction, we will have to just
wait and see what future technology looks like.

## Artificial General Intelligence

As for AI innovations, we should obviously mention Artificial General
Intelligence (AGI). AI researchers all over the world are working
towards this end goal, this system that mimics the intelligence of a
human being. How truly marvelous would this be? The possible societal
impact this system would have would be extraordinary, but scientific
admiration aside we should still be a couple of decades away
[@berruti_nel_whiteman_2021].

Today, we have systems that are excellent at a multitude of tasks
[@https://doi.org/10.48550/arxiv.2205.06175], but are still domain
constrained. Meaning they can't learn new situations by themselves, they
just reference a \"database\" for a particular signal similar to the one
it's presented with. However, scientists at DeepMind argue that through
Reinforcement Learning, the technique used to construct these systems,
we could induce the model into figuring out it's environment and
actually learning [@Silver2021].

Similar to what we've seen in the past, as long as these systems
continue to deliver on their promises, funding is very unlikely to
falter and summer should be indefinite. But the future is also uncertain
and technological barriers might be hit, halting research progress and
compromising the future of AI.

## Regulations

Lastly, with great innovation comes great responsibility: proportional
to the widespread adoption of these technologies are the dangers they
might pose. Consider a possibly biased system making a life altering
decision, we might have a faulty AI deciding whether someone gets a loan
or not, deciding whether they deserve parole, amongst many others.

It's up to the governments to regulate these systems and find ways to
protect their citizens from these models' shortcomings. Of course,
researchers need to be wary of these problems when developing their
models and balance the innovation versus risk scale. In fact, there has
been a substantial amount of research in this direction, especially in
the interpretability of models [@osullivan_2020], in the robustness
of models [@pmlr-v119-bojchevski20a] and privacy respecting models
[@Dwork2006DifferentialP]. However, this is a relatively young research
topic and a lot of work is still to be complete.

Moreover, when we consider the European Commission's statement on AI
[@eu_on_AI], they absolutely recognize the potential these technologies
have for the EU and hope to bolster investment in the member states, all
while remaining cautious for problems that this might introduce and
prioritizing the well-being of European citizens.

# Conclusion

The future of AI lies somewhere in a harmonic compromise between
innovation and regulation. As long as intelligent systems continue to
improve and reach their proposed goals, we'll be living in a never
ending AI summer.

However, we shouldn't fail to consider the risks it might bring and how
they might pose a challenge to humanity. How many jobs will be replaced
with intelligent systems? How will these workers be paid? Are we going
to observe an exodus into AI and programming jobs? But not all the
population is suited for these areas. Governments and prominent thinkers
throughout the world need to seriously consider these problems, and they
shouldn't take too long, or AI might just surprise them.

Additionally, on a personal note, I am very much excited to watch this
all unveil. All in all, If successful, AI is bound to become an
extraordinary revolution to the structure of our society, as its impacts
will be sure to be unprecedented.
